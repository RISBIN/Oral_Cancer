# CHAPTER 5: SYSTEM DESCRIPTION

## Overview

The OralCare AI system is a comprehensive web-based platform designed to assist healthcare professionals in the early detection of oral cancer through artificial intelligence-powered image analysis. The system combines cutting-edge deep learning algorithms with an intuitive user interface to provide rapid, accurate screening of oral lesion photographs, enabling healthcare providers to make informed clinical decisions and improve patient outcomes through earlier intervention. Built on a modern technology stack leveraging Django web framework, PostgreSQL database, TensorFlow machine learning library, and Supabase cloud services, the system delivers enterprise-grade reliability, security, and performance while remaining accessible to users with varying levels of technical expertise. The platform supports multiple user roles including doctors who perform screenings, administrators who manage the system, researchers who analyze aggregate data, and students who use the platform for educational purposes, recognizing that effective healthcare AI must serve diverse stakeholders within the medical ecosystem.

The architectural design follows a three-tier pattern separating presentation, application logic, and data management into distinct layers that can evolve independently while maintaining clean interfaces between components. The presentation layer consists of responsive web interfaces accessible through modern browsers on desktop computers, tablets, and smartphones, ensuring that healthcare providers can access the system from diverse computing environments without requiring specialized hardware or software installations. The application layer implements business logic including user authentication and authorization, image upload and validation, AI model inference orchestration, results management, report generation, and administrative functions, all coordinated through the Django framework's model-view-template architecture. The data layer manages persistent storage of structured data in PostgreSQL database tables and unstructured files in Supabase object storage, with careful attention to data integrity, security, and performance optimization through appropriate indexing and query design.

## Core Functional Modules

### User Management Module

The user management module provides comprehensive capabilities for account creation, authentication, profile management, and access control that form the foundation upon which all other system functionality depends. New users register through a multi-step form capturing essential information including name, email, username, password, role (doctor, researcher, student, or admin), and optional details like institutional affiliation and contact information. The registration process implements robust validation ensuring email uniqueness to prevent duplicate accounts, password strength requirements enforcing minimum length and complexity rules, and role-based approval workflows where administrator accounts require manual approval while other roles are automatically activated. Upon successful registration, users receive email verification links confirming their email addresses before gaining full system access, preventing account creation with invalid or fraudulent email addresses.

Authentication follows industry best practices with passwords hashed using PBKDF2 algorithm with sufficient iterations to resist brute-force attacks, session management through secure HTTP-only cookies preventing JavaScript access to session tokens, and automatic logout after configurable inactivity periods protecting against unauthorized access on shared workstations. The login interface accepts either email or username as identifier for user convenience, implements rate limiting to prevent credential stuffing attacks, and provides password reset functionality through email-based token verification. Multi-factor authentication support could be added in future versions for environments requiring additional security beyond passwords.

Profile management enables users to update their information including name, institution, contact details, and profile picture, with changes audited in the user activity log for accountability. Role-based access control restricts functionality based on user roles, with doctors accessing clinical features like image upload and report generation, researchers viewing aggregate analytics and export capabilities, students accessing practice cases and learning modules, and administrators managing all system aspects including user accounts, system configuration, and monitoring dashboards. Permission checks occur at multiple layers including URL routing restrictions, view-level decorators, template conditional rendering, and database query filtering ensuring that authorization is enforced consistently throughout the application.

### Image Upload and Management Module

The image upload module implements a user-friendly interface for healthcare providers to submit oral lesion photographs for AI analysis while ensuring that uploaded files meet quality and security requirements. The upload interface supports multiple input methods including drag-and-drop interaction where users can drag image files from their desktop onto a designated drop zone, click-to-browse dialog accessing the operating system's file picker, and direct camera capture on mobile devices enabling real-time photography during patient examinations. Visual feedback throughout the upload process includes hover effects when files are dragged over the drop zone, progress bars showing upload completion percentage, thumbnail previews confirming correct file selection, and clear success or error notifications indicating upload outcome.

File validation implements multiple checks ensuring uploaded images are appropriate for AI analysis. Type validation accepts only JPEG and PNG formats as these are the standard medical imaging formats supported by the AI models, rejecting other file types like GIF, BMP, or document formats with clear error messages explaining the restriction. Size validation enforces a 10 megabyte maximum limit preventing excessively large uploads that could impact system performance, with the limit chosen to accommodate high-resolution clinical photographs while excluding uncompressed or unnecessarily large files. Resolution validation could optionally check minimum dimensions ensuring images have sufficient detail for accurate AI analysis, though the current implementation accepts any resolution and resizes images during preprocessing.

Upon successful validation, images are stored in Supabase Storage with carefully constructed storage paths organizing files by user, date, and unique identifier following the pattern `{user_id}/{year}/{month}/{day}/{image_id}_{filename}`. This hierarchical structure enables efficient retrieval, simplifies backup and archival operations, and prevents filename collisions even when multiple users upload files with identical names. The storage system generates public URLs for each uploaded file enabling direct browser access for display in user interfaces, while maintaining access controls through Supabase's row-level security policies ensuring users can only access their own images unless granted broader permissions through their role.

Image metadata including filename, file size, upload timestamp, storage URL, and current processing status is recorded in the PostgreSQL database enabling quick searches and filters without accessing the storage system. The images table maintains relationships to the uploading user through foreign key constraints ensuring referential integrity, and tracks processing lifecycle through status fields indicating whether images are pending analysis, currently being processed, successfully analyzed, or failed processing with error details. Users can view their complete upload history through gallery interfaces showing thumbnail previews, upload dates, analysis status, and quick action buttons to view results or delete images.

### AI Detection Module

The AI detection module implements the core machine learning functionality that distinguishes OralCare AI from traditional image management systems, applying state-of-the-art convolutional neural networks to classify oral lesion images as potentially cancerous or non-cancerous with associated confidence scores. The module orchestrates a multi-step pipeline beginning with image preprocessing to prepare uploaded photographs for model inference, parallel execution of two distinct AI architectures for robust predictions, and storage of results in structured format enabling subsequent analysis and reporting.

Image preprocessing transforms uploaded files from their original formats and dimensions into the standardized representation required by the neural network models. The preprocessing pipeline begins by loading the image file from Supabase Storage into memory as a NumPy array representing pixel values, converting color space to RGB if necessary to ensure consistent color representation, and resizing to 224x224 pixels using high-quality Lanczos resampling that preserves image details better than simpler methods like nearest-neighbor or bilinear interpolation. Pixel value normalization scales intensities to the range expected by the models based on their training, typically zero-centered with unit variance or scaled to the [0,1] interval, ensuring that model weights optimized during training apply appropriately to inference inputs.

The system executes inference on two complementary AI architectures providing cross-validation of predictions. RegNetY320, representing modern neural architecture search designs that systematically optimize network structure, serves as the primary detection model achieving approximately 89.4% accuracy on validation datasets through efficient feature extraction and classification. VGG16, while representing an older generation of manually designed architectures, provides a proven baseline with 73.7% accuracy serving as comparison and validation for RegNetY320 predictions. Both models process the same preprocessed image through their respective convolutional layers, pooling operations, and fully connected classifiers to produce probability scores indicating confidence that the lesion is malignant.

Model outputs are post-processed to generate user-friendly predictions converting probability scores into binary classifications (Cancer or Non-Cancer) based on threshold values optimized during model validation, typically 0.5 meaning predictions above 50% confidence are classified as positive. The system records both the raw confidence score preserving full model output precision and the binary classification simplifying interpretation for clinical users. Processing metadata including inference time measured in seconds, model version identifiers enabling tracking of which model weights produced each prediction, and timestamps recording when analysis occurred are stored alongside prediction results supporting performance monitoring and quality assurance.

Detection results are persisted in the database with foreign key relationships linking each result to its source image and the user who requested analysis, enabling queries like finding all predictions for a specific image, comparing predictions across different model versions, or analyzing a user's detection history. The dual-model approach enables sophisticated analysis including consensus detection where both models agree on classification increasing confidence, disagreement identification flagging cases where models produce different predictions suggesting closer examination may be warranted, and model performance comparison tracking which architecture performs better on specific lesion types or patient populations.

### Results Management Module

The results management module provides comprehensive interfaces for users to review AI predictions, compare model outputs, examine confidence metrics, and navigate to related functionality like report generation or re-analysis. The primary results display shows the uploaded image alongside prediction outputs from both AI models, with visual design emphasizing critical information while maintaining professional medical aesthetic appropriate for clinical contexts.

The results interface presents each model's prediction prominently using color-coded indicators where potential cancer detections are highlighted in red or orange warning colors demanding attention, while non-cancer classifications use green or blue colors suggesting lower concern. Confidence scores are displayed both numerically as percentages (e.g., 87.3% confidence) and graphically through progress bars or circular gauges providing at-a-glance assessment of prediction certainty. The dual-model comparison view positions RegNetY320 and VGG16 predictions side-by-side enabling immediate identification of agreement or disagreement, with consensus highlighted when both models produce the same classification increasing clinical confidence in the result.

Interactive features enhance results exploration including image zoom capabilities allowing providers to examine lesion details in high resolution, toggle between original uploaded image and preprocessed image showing what the AI models actually analyzed, and timeline views for images with multiple analyses showing how predictions evolve over time or across model versions. Action buttons provide quick access to related functionality including generate report button launching the PDF report creation workflow, re-analyze button triggering new inference useful when models are updated, download original image retrieving the source file, and delete result removing the analysis while optionally preserving the source image.

The detection history interface aggregates all results for a user in searchable, filterable tables showing upload date, image filename, predictions from both models, confidence scores, and status indicators. Filters enable finding specific subsets like all cancer detections for further review, all images from a specific date range, or all results with model disagreement warranting closer examination. Sorting options organize results by date, confidence score, or model prediction enabling various analytical perspectives. Bulk actions allow selecting multiple results for batch operations like generating combined reports, exporting to CSV for external analysis, or archiving completed cases.

### Report Generation Module

The report generation module creates professional PDF documents suitable for medical records, patient communication, and specialist consultation, transforming raw AI predictions and images into polished reports meeting clinical documentation standards. The report generation workflow begins with a form capturing patient information and clinical context including optional patient name and demographics respecting privacy when anonymity is required, medical record number linking the report to institutional patient records, clinical notes capturing the provider's observations and assessment, and report preferences selecting which information to include in the final document.

The PDF generation process assembles multiple information sources into a coherent document following a standard medical report structure. The report header includes institutional branding if configured, report title and generation date, patient identifiers as provided while respecting omission if not entered, and provider information identifying who created the report. The clinical summary section embeds the oral lesion image with appropriate sizing ensuring clarity without excessive file size, presents AI predictions from both models with confidence scores, highlights consensus or disagreement between models, and includes provider's clinical notes adding human context to algorithmic predictions.

The recommendations section provides standardized guidance based on prediction results, suggesting biopsy and specialist referral for positive cancer predictions, follow-up observation protocols for suspicious but not definitive cases, and reassurance with recommended screening intervals for negative predictions. Disclaimer text clearly states that AI predictions are screening tools requiring clinical judgment rather than definitive diagnoses, protecting both system operators and users from liability while setting appropriate expectations about AI capabilities. The report footer includes generation timestamp, AI model versions used, system identifier, and digital signature placeholder for provider authentication.

Generated PDFs are uploaded to Supabase Storage following similar organizational structure as images, with public URLs enabling direct download and references stored in the database linking reports to their source detection results and generating users. Report metadata including patient name when provided, generation timestamp, file size, and storage location is recorded enabling search and retrieval functionality. Users can access their complete report history through dedicated interfaces, regenerate reports with modified parameters, or delete outdated reports while preserving underlying detection results.

### Administrative Dashboard Module

The administrative dashboard provides system administrators with comprehensive tools for user management, system monitoring, configuration, and analytics enabling effective operation and continuous improvement of the OralCare AI platform. The dashboard presents key metrics and visualizations giving at-a-glance insight into system health and usage including total registered users segmented by role, total images uploaded and analyzed with trend visualization, detection statistics showing cancer vs non-cancer predictions, and system performance metrics like average processing time and error rates.

User management interfaces enable administrators to view all user accounts in searchable tables, create new accounts manually with role assignment, edit user details including role changes or institution updates, deactivate or reactivate accounts controlling access, and delete accounts with cascade or preservation of associated data. Bulk operations support managing multiple users simultaneously like sending announcement emails, changing roles in batch, or exporting user lists. Detailed user activity logs show authentication events, upload actions, analysis requests, report generation, and administrative actions providing audit trails for security and compliance.

System monitoring dashboards track operational metrics including server resource utilization showing CPU, memory, and storage consumption, database performance metrics like query times and connection pool status, AI inference performance measuring model latency and throughput, and error rates with detailed logs for troubleshooting. Alert configuration enables setting thresholds for automated notifications when metrics exceed acceptable ranges, ensuring rapid response to degraded performance or outages. Integration with external monitoring services like Sentry for error tracking or Datadog for infrastructure monitoring could extend observability capabilities.

The configuration interface provides settings management including email configuration for verification and notifications, storage settings adjusting upload limits and retention policies, AI model configuration selecting which models are active and confidence thresholds, and security settings including session timeouts and password requirements. System-wide announcements can be composed and displayed to all users communicating maintenance windows, new features, or policy updates. Data export functionality enables administrators to generate comprehensive reports for regulatory compliance, research purposes, or data migration.

## Technical Implementation Details

The system is implemented using modern web technologies carefully selected for their maturity, performance, security, and developer productivity. Django 5.0 serves as the primary web framework providing robust foundations including ORM for database operations, template engine for HTML generation, authentication and authorization, form handling and validation, admin interface, and security features protecting against common web vulnerabilities. The application is organized following Django's app structure with separate apps for accounts, detection, reports, and dashboard each encapsulating related functionality with minimal coupling.

The database layer uses PostgreSQL 15 hosted on Supabase providing relational data management with ACID guarantees, advanced features like JSON fields and full-text search, horizontal scalability through read replicas, and automated backup and recovery. The schema is normalized to third normal form reducing redundancy while maintaining query performance through strategic indexing. UUID primary keys provide global uniqueness enabling distributed operations and preventing ID enumeration attacks.

The AI layer implements TensorFlow 2.15 models for inference with trained RegNetY320 and VGG16 weights loaded at application startup for minimal latency. Model serving occurs on CPU or GPU depending on infrastructure configuration, with GPU acceleration providing 5-10x faster inference at higher cost. The preprocessing pipeline is optimized for performance through efficient NumPy operations and minimal disk I/O. Future enhancements could include model quantization for faster inference, batch processing for higher throughput, or model updates through automated retraining pipelines.

The frontend employs responsive design using Bootstrap 5 framework ensuring interfaces adapt to different screen sizes, jQuery for interactive features and AJAX requests, and custom CSS for branding and specialized components. JavaScript validation provides immediate feedback on user inputs while server-side validation ensures security regardless of client-side manipulation. Progressive enhancement ensures core functionality works even with JavaScript disabled while enhanced features activate when available.

Deployment infrastructure uses Nginx as reverse proxy and static file server, Gunicorn as WSGI application server spawning multiple worker processes, and Supabase for database and file storage with automatic scaling. The system can be containerized using Docker for consistent deployment across environments and orchestrated through Kubernetes for production-scale operations requiring high availability and horizontal scaling. SSL/TLS encryption protects all data in transit while encryption at rest secures stored data.

The OralCare AI system thus represents a comprehensive, production-ready implementation of AI-assisted oral cancer screening, combining sophisticated machine learning with thoughtful user experience design and robust engineering practices to deliver a tool that can meaningfully improve early detection rates and patient outcomes.

